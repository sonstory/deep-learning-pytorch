{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b0707d",
   "metadata": {},
   "source": [
    "# 2.1 파이토치 개요\n",
    "- 파이토치란, GPU에서 텐서 조작 및 동적 신경망 구축이 가능한 프레임워크\n",
    "- GPU(Graphics Processing Unit) : 연산 속도를 빠르게 하는 역할\n",
    "    - 딥러닝에서는 기울기를 계산할 때 미분을 쓰는데, GPU를 사용하면 빠른 계산이 가능\n",
    "    - 내부적으로 CUDA, cuDNN이라는 API를 통해 GPU 연산을 사용\n",
    "    - 병렬 연산에서 GPU의 속도는 CPU의 속도보다 훨씬 빠르므로 딥러닝 학습에서 GPU 사용은 필수\n",
    "- 텐서(Tensor)\n",
    "    - 파이토치의 데이터 형태\n",
    "    - 단일 데이터 형식으로 된 자료들의 다차원 행렬\n",
    "    - 간단한 명령어(변수 뒤에 .cuda()를 추가)를 사용해서 GPU로 연산을 수행\n",
    "    - 벡터는 1차원 축(행, axis=0), 행렬은 2차원 축(열, axis=1), 텐서는 3차원 축(채널, axis=12)\n",
    "- 동적 신경망\n",
    "    - 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망\n",
    "        - ex> 학습 중에 은닉층을 추가하거나, 제거하는 등 모델의 네트워크 조작이 가능\n",
    "    -  연산 그래프를 정의하는 것과 동시에 값도 초기화되는 'Define by Run' 방식을 사용 -> 코드를 이해하기 쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150494d",
   "metadata": {},
   "source": [
    "# 2.2 파이토치 기본 문법\n",
    "## 2.2.1 텐서 다루기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746cd520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 생성 및 변환\n",
    "print(torch.tensor([[1,2],[3,4]]))\n",
    "print('------------------------')\n",
    "print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\"))\n",
    "print('------------------------')\n",
    "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5803b7",
   "metadata": {},
   "source": [
    "- 텐서는 파이토치의 가장 기본이 되는 데이터 구조로, 넘파이의 ndarray와 비슷하며 GPU에서의 연산도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f227d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 ndarray로 변환\n",
    "temp = torch.tensor([[1,2], [3,4]])\n",
    "print(temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9792f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2], [3,4]])\n",
    "print(temp.to(\"cpu\").numpy()) # 텐서를 CPU의 텐서로 변환한 후 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b714888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 인덱스 조작\n",
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca4e7f",
   "metadata": {},
   "source": [
    "- 텐서는 넘파이의 ndarray를 조작하는 것과 유사하게 동작하기 때문에 배열처럼 인덱스를 바로 지정하거나 슬라이스 등을 사용 가능\n",
    "- 텐서의 자료형\n",
    "    - torch.FloatTensor : 32비트의 부동 소수점\n",
    "    - torch.DoubleTensor : 64비트의 부동 소수점\n",
    "    - torch.LongTensor : 64비트의 부호가 있는 정수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edad502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 연산\n",
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5960f",
   "metadata": {},
   "source": [
    "- 텐서 간 타입이 다르면 연산이 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2108506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 차원 변경\n",
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1))\n",
    "print('------------------------')\n",
    "print(temp.view(-1))\n",
    "print('------------------------')\n",
    "print(temp.view(1, -1))\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af86667",
   "metadata": {},
   "source": [
    "## 2.2.2 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c5a85",
   "metadata": {},
   "source": [
    "### 커스텀 데이터셋을 만들어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ab4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.label = pd.read_csv(csv_file)\n",
    "    \n",
    "    # 전체 데이터셋의 크기 반환\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    # 전체 x와 y번째 데이터 중에 해당 idx번째의 데이터를 가져옴\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "        label = torch.tensor(self.label.iloc[idx,3]).int()\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206416bf",
   "metadata": {},
   "source": [
    "- 대량의 데이터를 이용하여 모델을 학습시킬 때 데이터를 한 번에 메모리에 불러와서 훈련시키면 시간과 비용 측면에서 비효율\n",
    "- 데이터를 한 번에 다 부르지 않고 조금씩 나누어 불러서 사용하는 방식이 `커스텀 데이터셋(custom dataset)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a79e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = CustomDataset('./car_evaluation.csv')\n",
    "dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525c439",
   "metadata": {},
   "source": [
    "#### 데이터로더(DataLoader)\n",
    "- 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용\n",
    "- 데이터를 미리 잘라 놓는 것이 아니라 내부적으로 반복자(iterator)에 포함된 인덱스(index)를 이용하여 배치 크기만큼 데이터를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91b9af",
   "metadata": {},
   "source": [
    "### 파이토치에서 제공하는 데이터셋 사용\n",
    "torchvision은 파이토치에서 제공하는 데이터셋들이 모여 있는 패키지(MNIST, ImageNet 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (1.0,)) # 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포(normalize)를 조정\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29af899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "\n",
    "download_root = '../MNIST_DATASET' # 내려받을 경로\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True) # 훈련 데이터셋\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True) # 검증 데이터셋\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True) # 테스트 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe369a21",
   "metadata": {},
   "source": [
    "## 2.2.3 모델 정의\n",
    "- 파이토치에서 모델을 정의하기 위해서는 모듈(module)을 상속한 클래스를 사용\n",
    "    - 계층(layer) : 모듈 또는 모듈을 구성하는 한 개의 계층으로 합성곱층(convolutional layer), 선형 계층(linear layer) 등\n",
    "    - 모듈(module) : 한 개 이상의 계층이 모여서 구성된 것으로, 모듈이 모여 새로운 모듈을 만들 수도 있음\n",
    "    - 모델(model) : 최종적으로 원하는 네트워크로, 한 개의 모듈이 모델이 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82d413",
   "metadata": {},
   "source": [
    "## 2.2.4 모델의 파라미터 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e799a",
   "metadata": {},
   "source": [
    "- 손실 함수(loss function)\n",
    "    - 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 측정\n",
    "    - 오차 값이 클수록 손실 함수의 값이 크고, 오차 값이 작을수록 손실 함수 값이 작아짐\n",
    "    - 손실 함수 값을 최소화하는 가중치와 바이어스를 찾는 것이 학습 목표\n",
    "    - BCELoss(이진 분류), CrossEntropyLoss(다중 클래스 분류), MSELoss(회귀)\n",
    "- 옵티마이저(optimizer)\n",
    "    - 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정\n",
    "    - optimizer는 step() 메서드를 통해 전달받은 파라미터를 업데이트\n",
    "    - 모델의 파라미터별로 다른 기준(ex> 학습률)을 적용 가능\n",
    "    - torch.optim.Optimizer(params, defaults)는 모든 옵티마이저의 기본이 되는 클래스\n",
    "    - zero_grad() 메서드는 옵티마이저에 사용된 파라미터들의 기울기(gradient)를 0으로 만듬\n",
    "    - torch.optim.lr_scheduler는 에포크에 따라 학습률을 조절\n",
    "- 학습률 스케줄러(learning rate schedular)\n",
    "    - 미리 지정한 횟수의 에포크를 지날 때마다 학습률을 감소(decay)\n",
    "    - 학습 초기에는 빠른 학습을 진행하다 전역 최소점(global minimum) 근처에 다다르면 학습률을 줄여서 최적점을 찾음\n",
    "- 지표(metrics) : 훈련과 테스트 단계를 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97719e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimzer=optimizer,\n",
    "                                             lr_lambda=lambda epoch : 0.95 ** epoch)\n",
    "\n",
    "for epoch in range(1,100+1): # 에포크 수만큼 데이터를 반복하여 처리\n",
    "    for x, y in dataloader: # 배치 크기만큼 데이터를 가져와서 학습 진행\n",
    "        optimizer.zero_grad()\n",
    "loss_fn(model(x), y).backward()\n",
    "optimizer.step()\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8123c7",
   "metadata": {},
   "source": [
    "## 2.2.5 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644aa5be",
   "metadata": {},
   "source": [
    "- 모델을 학습시킨다는 것은 y = wx + b라는 함수에서 적절한 w와 b를 찾는다는 의미\n",
    "- w와 b에 임의의 값을 적용하여 시작하며 오차가 줄어들어 전역 최소점에 이를 때까지 파라미터 (w,b)를 계속 수정\n",
    "- 딥러닝 학습 절차\n",
    "    - 1. 모델, 손실 함수, 옵티마이저 정의\n",
    "    - 2. 전방향 학습(입력 -> 출력 계산)\n",
    "    - 3. 손실 함수로 출력과 정답의 차이(오차) 계산\n",
    "    - 4. 역전파 학습(기울기 계산)\n",
    "    - 5. 기울기 업데이터\n",
    "- 파이토치 학습 절차\n",
    "    - 1. 모델, 손실 함수, 옵티마이저 정의\n",
    "    - 2. optimizer.zero_grad() : 전방향 학습, 기울기 초기화\n",
    "        - 기울기 값을 계산하기 위해 loss.backward() 메서드를 이용하면 새로운 기울기 값이 이전 기울기 값에 누적하여 계산됨\n",
    "        - 이는 RNN 모델을 구현할 땐 효과적이지만 누적 계산이 필요하지 않은 모델의 불필요\n",
    "        - 기울기를 구하는 과정에서의 미분 값이 누적되지 않게 초기화\n",
    "    - 3. output = model(input) : 출력 계산\n",
    "    - 4. loss = loss_fn(output, target) : 오차 계산\n",
    "    - 5. loss.backward() : 역전파 학습(기울기 자동 계산)\n",
    "    - 6. optimizer.step() : 기울기 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5286f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 예시\n",
    "for epoch in range(100):\n",
    "    yhat = model(x_train)\n",
    "    loss = criterion(yhat, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a76566",
   "metadata": {},
   "source": [
    "## 2.2.6 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "# 함수를 이용하여 모델 평가\n",
    "preds = torch.randn(10,5).softmax(dim=-1)\n",
    "target = torch.randint(5,(10,))\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈을 이용하여 모델을 평가\n",
    "metric = torchmetrics.Accuracy() # 모델 평가(정확도) 초기화\n",
    "\n",
    "n_batches=10\n",
    "for i in range(n_batches):\n",
    "    preds = torch.randn(10,5).softmax(dim=-1)\n",
    "    target = torch.randint(5,(10,))\n",
    "    \n",
    "    acc = metric(preds, target)\n",
    "    print('Accuracy on batch {} : {}'.format(i, acc))\n",
    "    \n",
    "acc = metric.comput()\n",
    "print(\"Accuracy on all data : {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3abc3",
   "metadata": {},
   "source": [
    "## 2.2.7 훈련 과정 모니터링\n",
    "- 텐서보드를 이용하여 학습에 사용되는 각종 파라미터 값이 어떻게 변화하는지 손쉽게 시각화하여 성능을 추적하거나 평가\n",
    "- 텐서보드 사용 방법\n",
    "    - 1. 텐서보드를 설정(set up)\n",
    "    - 2. 텐서보드에 기록(write)\n",
    "    - 3. 텐서보드를 사용하여 모델 구조 확인\n",
    "- model.train() & model.eval()\n",
    "    - model.train() : 훈련 데이터셋에 사용하며 모델 훈련이 진행. 드롭아웃(dropout)이 활성화\n",
    "    - model.eval() : 모델을 평가할 때는 모든 노드를 사용하겠다는 의미로 검증과 테스트 데이터셋에 사용(dropout=False)\n",
    "        - 이 과정에선 역전파가 필요하지 않기 때문에 with torch.no_grad()를 사용해 기울기 값 저장 x -> 연산 시간 감소\n",
    "    - 이 둘을 선언해야 모델의 정확도를 높일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ff6b6",
   "metadata": {},
   "source": [
    "# 2.4 파이토치 코드 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7f5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e065aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('car_evaluation.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385421eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='output'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 분포\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "dataset.output.value_counts().plot(kind='pie', \n",
    "                                   autopct='%0.05f%%', \n",
    "                                   colors=['lightblue', 'lightgreen', 'orange', 'pink'], \n",
    "                                   explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b8114",
   "metadata": {},
   "source": [
    "- 허용 불가능한 데이터가 대부분(70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caef748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 범주형 타입으로 변환\n",
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']\n",
    "\n",
    "for category in categorical_columns: # 데이터를 범주형으로 변환\n",
    "    dataset[category] = dataset[category].astype('category')\n",
    "\n",
    "# 범주형 데이터의 단어를 숫자(넘파이 배열)로 변환\n",
    "price = dataset['price'].cat.codes.values\n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "# 두 개 이상의 넘파이 객체를 합침\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10] # 합쳐진 넘파이 배열 중 10개의 행을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbded46",
   "metadata": {},
   "source": [
    "- 범주형 데이터를 텐서로 변환하기 위한 절차\n",
    "    - 범주형 데이터 -> category 변환 -> 넘파이 배열(numpy array) -> 텐서(Tensor)\n",
    "- 파이토치로 모델을 학습하기 위해선 텐서 형태로 변환해야 하는데, 이는 넘파이 배열을 통해 가능\n",
    "- cat.codes는 어떤 클래스가 어떤 숫자로 매핑되어 있는지 확인하기 어려움\n",
    "- np.stack은 배열들을 새로운 축으로 합쳐 줌. 따라서 두 배열의 차원이 동일해야 함\n",
    "    - ex> (2,2) 넘파이 배열 2개를 합치면 (2,2,2)\n",
    "    - np.concatenate는 (2,2) 넘파이 배열 2개를 합치면 (4,2) -> axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b16e598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tactics\\AppData\\Local\\Temp/ipykernel_1440/262467741.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0, 0, 2, 1],\n",
       "        [3, 3, 0, 0, 2, 2],\n",
       "        [3, 3, 0, 0, 2, 0],\n",
       "        [3, 3, 0, 0, 1, 1],\n",
       "        [3, 3, 0, 0, 1, 2],\n",
       "        [3, 3, 0, 0, 1, 0],\n",
       "        [3, 3, 0, 0, 0, 1],\n",
       "        [3, 3, 0, 0, 0, 2],\n",
       "        [3, 3, 0, 0, 0, 0],\n",
       "        [3, 3, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 넘파이 배열을 텐서로 변환\n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d628d028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "# 타겟 피쳐 텐서 변환\n",
    "outputs = pd.get_dummies(dataset.output)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten() # 1차원 텐서로 변환\n",
    "\n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35047012",
   "metadata": {},
   "source": [
    "- get_dummies() : 문자를 숫자 (0,1) 즉 가변수(dummy variable)로 만들어 주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d02e2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "# 범주형 칼럼을 N차원으로 변환\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe27ad8",
   "metadata": {},
   "source": [
    "- 워드 임베딩은 유사한 단어끼리 유사하게 인코딩되도록 표현하는 방법으로, 높은 차원의 임베딩일수록 단어 간의 세부적인 관계 파악 가능\n",
    "    - 단일 숫자로 변환된 넘파이 배열을 N차원으로 변경하여 사용\n",
    "- 배열을 N차원으로 변환하기 위해 먼저 모든 범주형 칼럼에 대한 임베딩 크기(벡터 차원)을 정의\n",
    "    - 정해진 규칙은 없지만, 칼럼의 고유 값 수를 2로 나누는 것을 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60bb55c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 분리\n",
    "total_records = 1728\n",
    "test_records = int(total_records * .2) # 전체 데이터의 20%만 테스트 데이터로 활용\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records - test_records]\n",
    "categorical_test_data = categorical_data[total_records - test_records : total_records]\n",
    "train_outputs = outputs[:total_records - test_records]\n",
    "test_outputs = outputs[total_records - test_records : total_records]\n",
    "\n",
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3154a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 네트워크 생성\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        \n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols \n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1) # 넘파이의 concatenate와 같지만 대상이 텐서\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024aa306",
   "metadata": {},
   "source": [
    "- 클래스(class) 형태로 구현되는 모델은 nn.Module을 상속\n",
    "- init()은 모델에서 사용될 파라미터와 신경망을 초기화하기 위한 용도로 사용하며, 객체가 생성될 때 자동으로 호출\n",
    "    - self : 첫 번째 파라미터는 self로 지정. 자기 자신을 의미\n",
    "    - embedding_size : 범주형 칼럼의 임베딩 크기\n",
    "    - output_size : 출력의 크기\n",
    "    - layers : 모든 계층에 대한 목록\n",
    "    - p : 드롭아웃(기본값 0.5)\n",
    "- super().__init__()은 부모 클래스(Model 클래스)에 접근할 때 사용. super는 self를 사용 x\n",
    "- 모델의 네트워크 계층을 구축하기 위해 for 문을 이용하여 각 계층을 all_layers 목록에 추가\n",
    "    - Linear : 선형 계층(linear layer)은 입력 데이터에 선형 변환을 진행한 결과(y = Wx + b)\n",
    "        - y : 선형 계층의 출력 값, W : 가중치, x : 입력 값, b : 바이어스\n",
    "        - 선형 계층은 입력과 가중치를 곱한 후 바이어스를 더한 값\n",
    "    - ReLU : 활성화 함수\n",
    "    - BatchNorm1d : 배치 정규화(batch normalization) 용도로 사용\n",
    "        - 신경망 안에서 데이터의 평균과 분산을 조정. 일반적으로 평균이 0, 분산이 1이 되도록 정규화\n",
    "    - Dropout : 과적합 방지에 사용\n",
    "- forward() : 학습 데이터를 입력받아서 연산을 진행. 모델 객체를 데이터와 함꼐 호출하면 자동으로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85dce2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(4, 2)\n",
      "    (2): Embedding(4, 2)\n",
      "    (3): Embedding(3, 2)\n",
      "    (4): Embedding(3, 2)\n",
      "    (5): Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model 클래스의 객체 생성\n",
    "model = Model(categorical_embedding_sizes, 4, [200,100,50], p=0.4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfecd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 파라미터 정의\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc48da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU/GPU 사용 지정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbbcac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss : 1.52741945\n",
      "epoch:  26 loss : 1.32650769\n",
      "epoch:  51 loss : 1.24943876\n",
      "epoch:  76 loss : 1.15718710\n",
      "epoch: 101 loss : 1.03131664\n",
      "epoch: 126 loss : 0.92791313\n",
      "epoch: 151 loss : 0.79866332\n",
      "epoch: 176 loss : 0.74244434\n",
      "epoch: 201 loss : 0.68144894\n",
      "epoch: 226 loss : 0.64707524\n",
      "epoch: 251 loss : 0.62740403\n",
      "epoch: 276 loss : 0.61667812\n",
      "epoch: 301 loss : 0.60256380\n",
      "epoch: 326 loss : 0.58737302\n",
      "epoch: 351 loss : 0.58476651\n",
      "epoch: 376 loss : 0.58816105\n",
      "epoch: 401 loss : 0.57891464\n",
      "epoch: 426 loss : 0.57420576\n",
      "epoch: 451 loss : 0.57268906\n",
      "epoch: 476 loss : 0.56818658\n",
      "epoch: 500 loss: 0.5702716708\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data).cuda()\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss) # 반복할 때마다 오차를 aggregated_losses에 추가\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f'epoch: {i:3} loss : {single_loss.item():10.8f}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward() # 가중치를 업데이트하기 위해 손실 함수의 backward() 메서드 호출\n",
    "    optimizer.step() # 옵티마이저 함수의 step() 메서드를 이용해 기울기 업데이트\n",
    "    \n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7976304",
   "metadata": {},
   "source": [
    "- 25 에포크마다 출력된 오차 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "831bd05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55804962\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋으로 모델 예측\n",
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).cuda()\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d99774",
   "metadata": {},
   "source": [
    "- 훈련 데이터셋에서 도출된 손실 값과 비슷하므로 과적합은 발생하지 않았다고 판단 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7059f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.3786,  1.8727, -4.1513, -4.0648],\n",
      "        [ 3.9461,  2.3306, -5.4539, -5.2170],\n",
      "        [ 5.6013,  4.2029, -8.0732, -7.8284],\n",
      "        [ 3.0972,  1.7590, -3.6641, -3.7088],\n",
      "        [ 1.1371,  0.6732, -1.5635, -1.5018]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 모델의 예측 확인\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade6c14",
   "metadata": {},
   "source": [
    "- 모델 네트워크의 output_size=4이므로 출력층에 4개의 뉴런이 포함되어 출력\n",
    "- 실제 출력이 0이면 인덱스 0(ex>3.3786)의 값이 인덱스 1(ex>1.8727)의 값보다 높아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9718816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 값을 갖는 인덱스 확인\n",
    "y_val = y_val.cpu()\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a6204",
   "metadata": {},
   "source": [
    "- 인덱스가 0인 값이 인덱스가 1인 값보다 크므로 처리된 출력이 0임을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c22924ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258   1]\n",
      " [ 85   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       259\n",
      "           1       0.50      0.01      0.02        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.63      0.50      0.44       345\n",
      "weighted avg       0.69      0.75      0.65       345\n",
      "\n",
      "0.7507246376811594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 테스트 데이터셋을 이용한 정확도 확인\n",
    "y_val = y_val.cpu()\n",
    "test_outputs = test_outputs.cpu()\n",
    "\n",
    "print(confusion_matrix(test_outputs, y_val))\n",
    "print(classification_report(test_outputs, y_val))\n",
    "print(accuracy_score(test_outputs, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
